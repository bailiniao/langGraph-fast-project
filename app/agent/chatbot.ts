import '../utils/loadEnv';
import {
  StateGraph,
  MessagesAnnotation,
  START,
  END,
} from '@langchain/langgraph';
import { ChatOpenAI } from '@langchain/openai'; // æ›¿æ¢ Google GenAI ä¸º OpenAI
import { HumanMessage } from '@langchain/core/messages';
import { SqliteSaver } from '@langchain/langgraph-checkpoint-sqlite';
import path from 'path';
import Database from 'better-sqlite3';
import { initSessionTable } from './db';
import { getEnabledToolsConfig } from './config/tools.config'; // ä¿®æ”¹å¯¼å…¥

// å­˜å‚¨å½“å‰æ¨¡å‹åç§°çš„å…¨å±€å˜é‡
let currentModelName: string = process.env.OPENAI_MODEL_NAME || 'qwen3-max';

// åˆ›å»ºæ¨¡å‹å·¥å‚å‡½æ•°ï¼Œæ ¹æ®æ¨¡å‹åç§°åŠ¨æ€åˆ›å»º ChatOpenAI å®ä¾‹
function createModel(modelName: string) {
  console.log('åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼Œä½¿ç”¨æ¨¡å‹:', modelName); // æ·»åŠ è°ƒè¯•æ—¥å¿—
  return new ChatOpenAI({
    model: modelName,
    openAIApiKey: process.env.OPENAI_API_KEY,
    configuration: {
      baseURL: process.env.OPENAI_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    },
    temperature: 0.7,
    streaming: true, // å¯ç”¨æµå¼å“åº”
  });
}

// èŠå¤©èŠ‚ç‚¹ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤
async function chatbotNode(state: typeof MessagesAnnotation.State) {
  // è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
  const lastMessage = state.messages[state.messages.length - 1];
  
  // æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·æ¶ˆæ¯
  if (lastMessage._getType() === 'human') {
    const userMessage = lastMessage.content.toString();
    
    // å°è¯•ä½¿ç”¨ç‰¹å®šå›å¤å·¥å…·
    try {
      const toolsConfig = getEnabledToolsConfig();
      const specificReplyTool = toolsConfig['specific_reply'];
      
      // å¦‚æœæœ‰ç‰¹å®šå›å¤å·¥å…·ï¼Œåˆ™ç›´æ¥è°ƒç”¨å…¶å¤„ç†å‡½æ•°
      if (specificReplyTool) {
        const reply = await specificReplyTool.handler({ message: userMessage });
        
        // å¦‚æœæœ‰ç‰¹å®šå›å¤ï¼Œåˆ™ç›´æ¥è¿”å›
        if (reply) {
          return { messages: [{ content: reply, type: 'ai' }] };
        }
      }
    } catch (error) {
      // å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å¤§æ¨¡å‹
      console.log('ç‰¹å®šå›å¤å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤§æ¨¡å‹:', error);
    }
  }
  
  // å¦‚æœæ²¡æœ‰ç‰¹å®šå›å¤ï¼Œåˆ™ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤
  // æ ¹æ®å½“å‰æ¨¡å‹åç§°åˆ›å»ºæ¨¡å‹å®ä¾‹
  const model = createModel(currentModelName);
  console.log('ä½¿ç”¨æ¨¡å‹:', currentModelName);
  const response = await model.invoke(state.messages);
  return { messages: [response] };
}

const dbPath = path.resolve(process.cwd(), 'chat_history.db');
export const db = new Database(dbPath);

// æ„å»ºæµå¼èŠå¤©æœºå™¨äººå›¾
const workflow = new StateGraph(MessagesAnnotation)
  .addNode('chatbot', chatbotNode)
  .addEdge(START, 'chatbot')
  .addEdge('chatbot', END);

// å¼‚æ­¥åˆå§‹åŒ–æ£€æŸ¥ç‚¹ä¿å­˜å™¨å’Œåº”ç”¨
let checkpointer: SqliteSaver;
let app: ReturnType<typeof workflow.compile>;

export const getCheckpointer = () => {
  if (!checkpointer) {
    // åˆ›å»º SQLite æ£€ç‚¹ä¿å­˜å™¨
    console.log('åˆå§‹åŒ– SqliteSaverï¼Œæ•°æ®åº“è·¯å¾„:', dbPath);
    try {
      // åˆå§‹åŒ–è‡ªå®šä¹‰ sessions è¡¨
      initSessionTable();
      checkpointer = new SqliteSaver(db);
      console.log('SqliteSaver åˆå§‹åŒ–æˆåŠŸ');
    } catch (error) {
      console.error('SqliteSaver åˆå§‹åŒ–å¤±è´¥:', error);
      throw error;
    }
  }
  return checkpointer;
};

async function initializeApp() {
  if (!checkpointer) {
    // åˆ›å»º SQLite æ£€ç‚¹ä¿å­˜å™¨
    console.log('åˆå§‹åŒ– SqliteSaverï¼Œæ•°æ®åº“è·¯å¾„:', dbPath);
    try {
      // ä½¿ç”¨ better-sqlite3 åˆ›å»ºæ•°æ®åº“è¿æ¥
      const db = new Database(dbPath);
      // åˆå§‹åŒ–è‡ªå®šä¹‰ sessions è¡¨
      initSessionTable();
      checkpointer = new SqliteSaver(db);
      console.log('SqliteSaver åˆå§‹åŒ–æˆåŠŸ');
    } catch (error) {
      console.error('SqliteSaver åˆå§‹åŒ–å¤±è´¥:', error);
      throw error;
    }
  }

  if (!app) {
    app = workflow.compile({ checkpointer });
  }

  return app;
}

// è·å–åº”ç”¨å®ä¾‹çš„å‡½æ•°
const getApp = async () => {
  return await initializeApp();
};

// è®¾ç½®å½“å‰æ¨¡å‹åç§°çš„å‡½æ•°
export function setCurrentModelName(modelName: string) {
  console.log('è®¾ç½®å½“å‰æ¨¡å‹åç§°ä¸º:', modelName); // æ·»åŠ è°ƒè¯•æ—¥å¿—
  currentModelName = modelName;
}

// æµå¼å“åº”ç¤ºä¾‹
async function runStreamingChatbot() {
  console.log('=== æµå¼èŠå¤©æœºå™¨äººç¤ºä¾‹ ===');

  const threadConfig = {
    configurable: { thread_id: 'streaming-demo' + Math.random() },
  };

  console.log('\n--- æµå¼å“åº”æ¼”ç¤º ---');
  console.log('ç”¨æˆ·: è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹ React çš„æ ¸å¿ƒæ¦‚å¿µ');
  console.log('AI: ', { newline: false });

  // ä½¿ç”¨ streamEvents è·å–æµå¼å“åº”
  for await (const event of app.streamEvents(
    {
      messages: [new HumanMessage('ä½ æ˜¯è°ï¼Ÿ')],
    },
    { version: 'v2', ...threadConfig }
  )) {
    // è¿‡æ»¤ LLM æµå¼è¾“å‡ºäº‹ä»¶
    if (event.event === 'on_chat_model_stream') {
      const chunk = event.data?.chunk;
      if (chunk?.content) {
        process.stdout.write(chunk.content);
      }
    }
  }

  console.log('\n\n--- å¦ä¸€ä¸ªæµå¼å“åº” ---');
  console.log('ç”¨æˆ·: èƒ½ç»™æˆ‘ä¸€äº›å­¦ä¹ å»ºè®®å—ï¼Ÿ');
  console.log('AI: ', { newline: false });

  for await (const event of app.streamEvents(
    {
      messages: [new HumanMessage('èƒ½ç»™æˆ‘ä¸€äº›å­¦ä¹ å»ºè®®å—ï¼Ÿ')],
    },
    { version: 'v2', ...threadConfig }
  )) {
    if (event.event === 'on_chat_model_stream') {
      const chunk = event.data?.chunk;
      if (chunk?.content) {
        process.stdout.write(chunk.content);
      }
    }
  }

  console.log('\n');
}

// æµå¼çŠ¶æ€æ›´æ–°ç¤ºä¾‹
async function runStreamingStates() {
  console.log('\n=== æµå¼çŠ¶æ€æ›´æ–°ç¤ºä¾‹ ===');

  const threadConfig = { configurable: { thread_id: 'state-streaming' } };

  console.log('\n--- ç›‘å¬çŠ¶æ€å˜åŒ– ---');

  // ä½¿ç”¨ stream æ–¹æ³•è·å–æ¯æ­¥çš„çŠ¶æ€æ›´æ–°
  const stream = await app.stream(
    {
      messages: [new HumanMessage('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±')],
    },
    { streamMode: 'updates', ...threadConfig }
  );

  for await (const chunk of stream) {
    console.log('çŠ¶æ€æ›´æ–°:', JSON.stringify(chunk, null, 2));
  }
}

// è‡ªå®šä¹‰æµå¼å¤„ç†å™¨
class StreamingHandler {
  private buffer: string = '';
  private onToken?: (token: string) => void;
  private onComplete?: (fullResponse: string) => void;

  constructor(options: {
    onToken?: (token: string) => void;
    onComplete?: (fullResponse: string) => void;
  }) {
    this.onToken = options.onToken;
    this.onComplete = options.onComplete;
  }

  async handleStream(
    graph: ReturnType<typeof workflow.compile>,
    input: { messages: HumanMessage[] },
    config: { configurable: { thread_id: string } }
  ) {
    this.buffer = '';

    for await (const event of graph.streamEvents(input, {
      version: 'v2',
      ...config,
    })) {
      if (event.event === 'on_chat_model_stream') {
        const chunk = event.data?.chunk;
        if (chunk?.content) {
          this.buffer += chunk.content;
          this.onToken?.(chunk.content);
        }
      }
    }

    this.onComplete?.(this.buffer);
    return this.buffer;
  }
}

// ä½¿ç”¨è‡ªå®šä¹‰æµå¼å¤„ç†å™¨çš„ç¤ºä¾‹
async function runCustomStreamingHandler() {
  console.log('\n=== è‡ªå®šä¹‰æµå¼å¤„ç†å™¨ç¤ºä¾‹ ===');

  const threadConfig = { configurable: { thread_id: 'custom-streaming' } };

  const handler = new StreamingHandler({
    onToken: (token) => {
      process.stdout.write(token);
    },
    onComplete: (fullResponse) => {
      console.log(`\n\n[å®Œæ•´å“åº”é•¿åº¦: ${fullResponse.length} å­—ç¬¦]`);
    },
  });

  console.log('\nç”¨æˆ·: è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯çŠ¶æ€ç®¡ç†');
  console.log('AI: ');

  await handler.handleStream(
    app,
    {
      messages: [new HumanMessage('è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯çŠ¶æ€ç®¡ç†')],
    },
    threadConfig
  );
}

// æ‰¹é‡æµå¼å¤„ç†ç¤ºä¾‹
async function runBatchStreaming() {
  console.log('\n=== æ‰¹é‡æµå¼å¤„ç†ç¤ºä¾‹ ===');

  const questions = ['ä»€ä¹ˆæ˜¯ç»„ä»¶ï¼Ÿ', 'ä»€ä¹ˆæ˜¯ Propsï¼Ÿ', 'ä»€ä¹ˆæ˜¯ Stateï¼Ÿ'];

  for (let i = 0; i < questions.length; i++) {
    const threadConfig = { configurable: { thread_id: `batch-${i}` } };

    console.log(`\n--- é—®é¢˜ ${i + 1}: ${questions[i]} ---`);
    console.log('AI: ');

    for await (const event of app.streamEvents(
      {
        messages: [new HumanMessage(questions[i])],
      },
      { version: 'v2', ...threadConfig }
    )) {
      if (event.event === 'on_chat_model_stream') {
        const chunk = event.data?.chunk;
        if (chunk?.content) {
          process.stdout.write(chunk.content);
        }
      }
    }

    console.log('\n');
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶
if (require.main === module) {
  // async function main() {
  //   // await runStreamingChatbot();
  //   // await runStreamingStates();
  //   // await runCustomStreamingHandler();
  //   // await runBatchStreaming();

  //   for await (const item of checkpointer.list({})) {
  //     console.log('%c Line:218 ğŸ­ item', 'color:#ea7e5c', item);
  //   }
  // }

  // main().catch(console.error);
  // åˆå§‹åŒ–é˜¿é‡Œäº‘åƒé—®æ¨¡å‹
  const model = new ChatOpenAI({
    model: process.env.OPENAI_MODEL_NAME || 'qwen3-max',
    openAIApiKey: process.env.OPENAI_API_KEY,
    configuration: {
      baseURL: process.env.OPENAI_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    },
    temperature: 0.7,
    streaming: true, // å¯ç”¨æµå¼å“åº”
  });
  model.invoke([new HumanMessage('ä½ å¥½')]).then(res => {

    console.log("%c Line:274 ğŸ§ res", "color:#42b983", res);
  }).catch(err => {
    console.log("%c Line:277 ğŸ¥› err", "color:#33a5ff", err);

  })
}

export {
  getApp,
  runStreamingChatbot,
  runStreamingStates,
  StreamingHandler,
  runCustomStreamingHandler,
  runBatchStreaming,
  checkpointer
};
